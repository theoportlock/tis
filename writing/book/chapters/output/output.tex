\chapter{Output}
\section{How are decisions made}
Decision field theory is a method of mathematically modelling the change in utility when comparing multiple choices \cite{busemeyer2002survey}.
Currently, machines do not act this way.
% the need for actions/outputs to be recognised by inputs for memory
% how do you determine if an action happens beacuse of you or someone else?
% talk if statements
% say that the action comes from humans interperating the computational results of machines
% look into jaccard similarty between binary strings
% action that is goverened by an asymmetric binary variable (i.e. the value of 1 is more important than 0) - there are way more things that it could not be than it could be - do we lose thee ability to view in negative?

\section{The random-pianist method}
% Difference between action and prediction
% compare to neurological likeness
% talk about the fact that people only do what they have observed before
% think about free will here (or maybe in the intro?)

\section{The Upgrade workflow}
% consequences of random actions on input are put into memory
% input and actions are memorised
% an input causes a precition - AB -> ABCT
%% if prediction was different, then action would be different
% The prediction is used as input to 
% when you predict an action you activate it
% How to measure the extent of influence of the new input from the consesequences of the actions of the old input - repeat
% The contribution of random to the action determines the level of understanding?
% If random get's it right then
No delayed combinations
only reinforce if you see it muliple times
I = input that does not result from an action
A = input that results from an action
R = random input (or choice of previous set: pseudorandom)
[] = combination expansion
Both the action and the actions effects should be recognised by combinations

I1, R1        -->    A1[I1, R1]
I2, A1, R2    -->    A2[I2, A1, R2]
I3, A2, R3    -->    A3[I3, A2, R3]
I4, A3, R4    -->    A4[I4, A3, R4]

Aims:
1: Learn actions from inputs
2: Decrease entropy from the UEI
3: Learn inputs from inputs

Whats being combined for each timepoint:
Random doping
I1, R1
I2, R2, A1[I1, R1]
I3, R3, A2[I2, R2, A1[I1, R1]]
...

actions included
I1, A1
I2, A1(I1)
I3, A2(I2), A2(A1(I1)), A2(I2 + A1(T1))

W/O random doping
I1
I2, A1[I1]
I3, A2[I2, A1[I1]]
...

expanded W/O random doping
I1
I2, A1(I1)
I3, A2(I2), A2(A1(I1)), A2(I2 + A1(T1))
...

translated:
new input
the action resulting from the second input
the action resulting from the action resulting from the first input
the action resulting from a combination of the second input and the action resulting from the first input 

R1, I1, A1
